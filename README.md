# Motion Gesture Recognition with use of Deep Learning
![motiongesture](https://github.com/KuntamukkalaPavanKumar/motion_gesture_recognition/blob/main/Guesture-recognition-technology-blog-feature-image.jpg)

## Abstract
The purpose of this project is to develop a deep neural network model for smart TV that can recognise five different gestures (Thumbs Up, Thumbs Down, Swipe Left, Swipe Right, Stop). The five different gestures performed by the user should control the TV without using a remote.
To make that happen, we used Conv3D, LSTM, GRU, Transfer Learning by opting MobileNetv1 to develop a model which will have great training and validation accuracy.
We chose 'Accuracy' as a metric to validate our models performance.
We came to find that GRU model with dropout layer added is performing with better Training and Validation accuracies as high as 90%.

## Dataset
There are 663 Gesture folders in Training Folder and 100 Gesture Folders in Validation Folder.
-In each folder we have 30 frames/ images.
-Due to computational constratint, we took only 15 frames (alternative) out of 30 frames during training phase.

## Experimentation:
-The Image size of train dataset contains 160 x 120 and 360 x 360. 
-We resized them to image of size 80 x 80. 
The reason for opting such size is computational and memory constraints on our side. Batch size, we took it as 32.
-Number of epoch runs we took as 20, 30, 50 depending on the model loss improvement and its improvement in the accuracy metric.

Before arriving to this final GRU model, we experimented with Conv3D, ConvLSTM2D, MobileNetv1.

1) Conv3D resulted in .h5 file size ranging from 500 MB to 2 GB and its training parameters came out to be 13 million to 19 million. The training and validation accuracies also came out to be very low.
2) ConvLSTM resulted in .h5 file size of 220 kb with number of training parameters as low as 13,000. But the training and validation accuracies are coming around 60% which is not satisfactory.
3) GRU resulted in .h5 file size of 250 kb with number of training parameters as 49,000 in number. The training and validation accuracies are coming around 89% at the end of 50 epoch runs.
4) MObilenetV1 with an addition GRU layer, dropout layer is giving parameters of number 3 million. But the training and validation accuracies are hovering around 60% which is not satisfactory.

After the above series of runs, by varying number of kernels, adopting GlobalAveragePooling3D instead of Flatten layer etc.,
We came to conclusion that GRU is the best performing model.
You can see its performance from the below graph.

### Model Evaluation:

![grumodel](https://github.com/KuntamukkalaPavanKumar/motion_gesture_recognition/blob/main/TimeDistributedGRU2epoch50.png)

### Architecture Specifications:
- Rescalling Layer - To rescale an input in the [0, 255] range to be in the [0, 1] range.
- Conv3D - Conv3D does convolution by treating time as another dimension in case of videos.
- Pooling Layer - Pooling layers are used to reduce the dimensions of the feature maps. Thus, it reduces the number of parameters to learn and the amount of computation performed in the network. The pooling layer summarises the features present in a region of the feature map generated by a convolution layer.
- Dropout Layer - The Dropout layer randomly sets input units to 0 with a frequency of rate at each step during training time, which helps prevent overfitting.
- Flatten Layer - Flattening is converting the data into a 1-dimensional array for inputting it to the next layer. We flatten the output of the convolutional layers to create a single long feature vector. And it is connected to the final classification model, which is called a fully-connected layer.
- Dense Layer - The dense layer is a neural network layer that is connected deeply, which means each neuron in the dense layer receives input from all neurons of its previous layer.
- Activation Function(ReLU) - The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero.The rectified linear activation function overcomes the vanishing gradient problem, allowing models to learn faster and perform better.
- Activation Function(Softmax) - The softmax function is used as the activation function in the output layer of neural network models that predict a multinomial probability distribution. The main advantage of using Softmax is the output probabilities range. The range will 0 to 1, and the sum of all the probabilities will be equal to one.